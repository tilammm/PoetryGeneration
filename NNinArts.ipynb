{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNinArts.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99DtLucTgVX6"
      },
      "source": [
        "# Requirenments installation\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyP9_tfXgkQH"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8FvznHsf-FE"
      },
      "source": [
        "!pip3 install urllib3==1.25.4\r\n",
        "!pip3 install transformers==2.8.0\r\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDYi1TVTrtkO"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5EtK-jerBRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf479b8-4147-429e-eeb8-7d96fbf27c92"
      },
      "source": [
        "data_path = \"drive/My Drive/data.txt\"\n",
        "!ls \"$data_path\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'drive/My Drive/data.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXdNbrq3rgzq"
      },
      "source": [
        "with open(data_path, \"r\") as file:\n",
        "    text = file.read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgqpozwryu_"
      },
      "source": [
        "valid_size = 15"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5XsmNzor0pK"
      },
      "source": [
        "topics = []\n",
        "all_essays = []\n",
        "for line in text.split(\"</s>\"):\n",
        "    if \"Тема:\" in line and \"Стихотворение:\" in line:\n",
        "        essay_text = line.split(\"Стихотворение:\")\n",
        "        if len(essay_text) == 2:\n",
        "            topic = essay_text[0].replace(\"<s>\", \" \").replace(\"</s>\", \" \").strip()\n",
        "            essay_text = essay_text[1].replace(\"<s>\", \" \").replace(\"</s>\", \" \").strip()\n",
        "            essay_text = f\"Стихотворение: {essay_text}\"\n",
        "            essay_res = f\"<s>{topic}\\n{essay_text}</s>\"\n",
        "            all_essays.append(essay_res)\n",
        "            topics.append(topic)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izc0lkkHr2Rz"
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tkc1_49r36X"
      },
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EHAdpt5r5B9"
      },
      "source": [
        "unique_topics = list(set(topics))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnPgMbHUcYnn",
        "outputId": "7c61330a-299c-4662-f391-76fee649d7e3"
      },
      "source": [
        "len(unique_topics)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUfoak6Hr6Ed"
      },
      "source": [
        "valid_topics = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x55W6Xf4r7MK"
      },
      "source": [
        "for _ in range(valid_size):\n",
        "    # Use randint for more speed (on big lists it is faster)\n",
        "    idx = np.random.randint(0, len(unique_topics))\n",
        "    valid_topics.append(unique_topics[idx])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "861f4lMGr8ez"
      },
      "source": [
        "import nltk\n",
        "\n",
        "\n",
        "train = []\n",
        "valid = []\n",
        "for topic, essay in zip(topics, all_essays):\n",
        "    is_train = True\n",
        "    for valid_topic in valid_topics:\n",
        "        if (\n",
        "            nltk.edit_distance(valid_topic, topic[:len(valid_topic)]) < 20 or\n",
        "            nltk.edit_distance(valid_topic[:len(topic)], topic) < 20 or\n",
        "            nltk.edit_distance(valid_topic[len(topic):], topic) < 20 or\n",
        "            nltk.edit_distance(valid_topic, topic[len(valid_topic):]) < 20\n",
        "            ):\n",
        "            is_train = False\n",
        "    if is_train:\n",
        "        train.append(essay)\n",
        "    else:\n",
        "        valid.append(essay)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T0gN6gqr9pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe377dbf-a14a-4a0c-e32d-da1a0156571f"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(168, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPB8rrVPr-kh"
      },
      "source": [
        "with open(\"train.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(train))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP5_nk_0sAB0"
      },
      "source": [
        "with open(\"valid.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(valid))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwINJqCQgzqf"
      },
      "source": [
        "# Model finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG8KaSIFnJbZ"
      },
      "source": [
        "import glob\r\n",
        "import logging\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import re\r\n",
        "import shutil\r\n",
        "from typing import Dict, List, Tuple\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from torch.nn.utils.rnn import pad_sequence\r\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\r\n",
        "from torch.utils.data.distributed import DistributedSampler\r\n",
        "from tqdm import tqdm, trange\r\n",
        "from transformers import (\r\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\r\n",
        "    WEIGHTS_NAME,\r\n",
        "    AdamW,\r\n",
        "    AutoConfig,\r\n",
        "    AutoModelWithLMHead,\r\n",
        "    AutoTokenizer,\r\n",
        "    PreTrainedModel,\r\n",
        "    PreTrainedTokenizer,\r\n",
        "    get_linear_schedule_with_warmup,\r\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d_VsEgqhyNP"
      },
      "source": [
        "# Model taken from https://github.com/sberbank-ai/ru-gpts\r\n",
        "data_path = \"train.txt\"\r\n",
        "batch_size = 1\r\n",
        "train_batch_size = 1\r\n",
        "num_train_epochs = 5\r\n",
        "gradient_accumulation_steps = 1\r\n",
        "model_path = 'sberbank-ai/rugpt3small_based_on_gpt2'\r\n",
        "learning_rate = 5e-5\r\n",
        "adam_epsilon = 1e-8\r\n",
        "logging_steps = 0\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLOB12PGpsZd"
      },
      "source": [
        "class TextDataset(Dataset):\r\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer, file_path: str, block_size=512):\r\n",
        "\r\n",
        "        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\r\n",
        "\r\n",
        "        directory, filename = os.path.split(file_path)\r\n",
        "\r\n",
        "        self.examples = []\r\n",
        "        with open(file_path, encoding=\"utf-8\") as f:\r\n",
        "            text = f.read()\r\n",
        "\r\n",
        "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\r\n",
        "\r\n",
        "        for i in range(0, len(tokenized_text) - block_size + 1, block_size): \r\n",
        "            self.examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i: i + block_size]))\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.examples)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        return torch.tensor(self.examples[item], dtype=torch.long)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6xa9NjRgUKc"
      },
      "source": [
        "def train(train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer):\r\n",
        "    \"\"\" Train the model \"\"\"\r\n",
        "    \r\n",
        "    def collate(examples: List[torch.Tensor]):\r\n",
        "        if tokenizer._pad_token is None:\r\n",
        "            return pad_sequence(examples, batch_first=True)\r\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\r\n",
        "\r\n",
        "    train_sampler = RandomSampler(train_dataset)\r\n",
        "    train_dataloader = DataLoader(\r\n",
        "        train_dataset, sampler=train_sampler, batch_size=train_batch_size, collate_fn=collate\r\n",
        "    )\r\n",
        "\r\n",
        "    t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\r\n",
        "\r\n",
        "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\r\n",
        "    model.resize_token_embeddings(len(tokenizer))\r\n",
        "\r\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\r\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\r\n",
        "    optimizer_grouped_parameters = [\r\n",
        "        {\r\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\r\n",
        "            \"weight_decay\": 0.01,\r\n",
        "        },\r\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\r\n",
        "    ]\r\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\r\n",
        "    scheduler = get_linear_schedule_with_warmup(\r\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=t_total\r\n",
        "    )\r\n",
        "    \r\n",
        "    # Check if saved optimizer or scheduler exist\r\n",
        "    if (\r\n",
        "            model_path\r\n",
        "            and os.path.isfile(os.path.join(model_path, \"optimizer.pt\"))\r\n",
        "            and os.path.isfile(os.path.join(model_path, \"scheduler.pt\"))\r\n",
        "    ):\r\n",
        "        # Load in optimizer and scheduler states\r\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(model_path, \"optimizer.pt\")))\r\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(model_path, \"scheduler.pt\")))\r\n",
        "\r\n",
        "    global_step = 0\r\n",
        "    epochs_trained = 0\r\n",
        "    steps_trained_in_current_epoch = 0\r\n",
        "\r\n",
        "    tr_loss, logging_loss = 0.0, 0.0\r\n",
        "\r\n",
        "    model.zero_grad()\r\n",
        "    train_iterator = trange(\r\n",
        "        epochs_trained, int(num_train_epochs), desc=\"Epoch\", disable=False\r\n",
        "    )\r\n",
        "    \r\n",
        "    for _ in train_iterator:\r\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\r\n",
        "        for step, batch in enumerate(epoch_iterator):\r\n",
        "\r\n",
        "            # Skip past any already trained steps if resuming training\r\n",
        "            if steps_trained_in_current_epoch > 0:\r\n",
        "                steps_trained_in_current_epoch -= 1\r\n",
        "                continue\r\n",
        "\r\n",
        "            inputs, labels = (batch, batch)\r\n",
        "            inputs = inputs.to(device)\r\n",
        "            labels = labels.to(device)\r\n",
        "            model.train()\r\n",
        "            outputs =  model(inputs, labels=labels)\r\n",
        "            loss = outputs[0]  \r\n",
        "\r\n",
        "            if gradient_accumulation_steps > 1:\r\n",
        "                loss = loss / gradient_accumulation_steps\r\n",
        "\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            tr_loss += loss.item()\r\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\r\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "                optimizer.step()\r\n",
        "                scheduler.step()  # Update learning rate schedule\r\n",
        "                model.zero_grad()\r\n",
        "                global_step += 1\r\n",
        "\r\n",
        "\r\n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWBSuxnrnOJC",
        "outputId": "c9cdd02b-02b6-416b-9e00-ab0a40d73bae"
      },
      "source": [
        " config = AutoConfig.from_pretrained(model_path)\r\n",
        " tokenizer = AutoTokenizer.from_pretrained(model_path)\r\n",
        "\r\n",
        " model = AutoModelWithLMHead.from_pretrained(\r\n",
        "            model_path,\r\n",
        "            from_tf=bool(\".ckpt\" in model_path),\r\n",
        "            config=config,\r\n",
        "        )\r\n",
        " model.to(device)\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50264, 768)\n",
              "    (wpe): Embedding(2048, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oe5-2Gty_JS"
      },
      "source": [
        "train_dataset = TextDataset(tokenizer, file_path=data_path, block_size=1024)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWfsO9mEqLDX",
        "outputId": "b8de43a0-a8a1-4072-98ed-e82068aabe90"
      },
      "source": [
        "global_step, tr_loss = train(train_dataset, model, tokenizer)\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:   1% 1/92 [00:00<01:12,  1.25it/s]\n",
            "Iteration:   2% 2/92 [00:01<01:06,  1.36it/s]\n",
            "Iteration:   3% 3/92 [00:02<01:02,  1.43it/s]\n",
            "Iteration:   4% 4/92 [00:02<00:59,  1.49it/s]\n",
            "Iteration:   5% 5/92 [00:03<00:57,  1.53it/s]\n",
            "Iteration:   7% 6/92 [00:03<00:54,  1.56it/s]\n",
            "Iteration:   8% 7/92 [00:04<00:53,  1.59it/s]\n",
            "Iteration:   9% 8/92 [00:05<00:52,  1.60it/s]\n",
            "Iteration:  10% 9/92 [00:05<00:51,  1.61it/s]\n",
            "Iteration:  11% 10/92 [00:06<00:50,  1.62it/s]\n",
            "Iteration:  12% 11/92 [00:06<00:49,  1.63it/s]\n",
            "Iteration:  13% 12/92 [00:07<00:49,  1.63it/s]\n",
            "Iteration:  14% 13/92 [00:08<00:48,  1.63it/s]\n",
            "Iteration:  15% 14/92 [00:08<00:47,  1.63it/s]\n",
            "Iteration:  16% 15/92 [00:09<00:47,  1.63it/s]\n",
            "Iteration:  17% 16/92 [00:09<00:46,  1.64it/s]\n",
            "Iteration:  18% 17/92 [00:10<00:45,  1.64it/s]\n",
            "Iteration:  20% 18/92 [00:11<00:45,  1.64it/s]\n",
            "Iteration:  21% 19/92 [00:11<00:44,  1.63it/s]\n",
            "Iteration:  22% 20/92 [00:12<00:44,  1.62it/s]\n",
            "Iteration:  23% 21/92 [00:13<00:43,  1.63it/s]\n",
            "Iteration:  24% 22/92 [00:13<00:43,  1.63it/s]\n",
            "Iteration:  25% 23/92 [00:14<00:42,  1.63it/s]\n",
            "Iteration:  26% 24/92 [00:14<00:41,  1.63it/s]\n",
            "Iteration:  27% 25/92 [00:15<00:41,  1.63it/s]\n",
            "Iteration:  28% 26/92 [00:16<00:40,  1.63it/s]\n",
            "Iteration:  29% 27/92 [00:16<00:39,  1.63it/s]\n",
            "Iteration:  30% 28/92 [00:17<00:39,  1.63it/s]\n",
            "Iteration:  32% 29/92 [00:17<00:39,  1.62it/s]\n",
            "Iteration:  33% 30/92 [00:18<00:38,  1.63it/s]\n",
            "Iteration:  34% 31/92 [00:19<00:37,  1.62it/s]\n",
            "Iteration:  35% 32/92 [00:19<00:36,  1.63it/s]\n",
            "Iteration:  36% 33/92 [00:20<00:36,  1.62it/s]\n",
            "Iteration:  37% 34/92 [00:21<00:35,  1.63it/s]\n",
            "Iteration:  38% 35/92 [00:21<00:35,  1.63it/s]\n",
            "Iteration:  39% 36/92 [00:22<00:34,  1.61it/s]\n",
            "Iteration:  40% 37/92 [00:22<00:33,  1.62it/s]\n",
            "Iteration:  41% 38/92 [00:23<00:33,  1.61it/s]\n",
            "Iteration:  42% 39/92 [00:24<00:32,  1.62it/s]\n",
            "Iteration:  43% 40/92 [00:24<00:32,  1.62it/s]\n",
            "Iteration:  45% 41/92 [00:25<00:31,  1.62it/s]\n",
            "Iteration:  46% 42/92 [00:25<00:30,  1.62it/s]\n",
            "Iteration:  47% 43/92 [00:26<00:30,  1.62it/s]\n",
            "Iteration:  48% 44/92 [00:27<00:29,  1.62it/s]\n",
            "Iteration:  49% 45/92 [00:27<00:28,  1.62it/s]\n",
            "Iteration:  50% 46/92 [00:28<00:28,  1.62it/s]\n",
            "Iteration:  51% 47/92 [00:29<00:27,  1.62it/s]\n",
            "Iteration:  52% 48/92 [00:29<00:27,  1.62it/s]\n",
            "Iteration:  53% 49/92 [00:30<00:26,  1.62it/s]\n",
            "Iteration:  54% 50/92 [00:30<00:25,  1.62it/s]\n",
            "Iteration:  55% 51/92 [00:31<00:25,  1.61it/s]\n",
            "Iteration:  57% 52/92 [00:32<00:24,  1.61it/s]\n",
            "Iteration:  58% 53/92 [00:32<00:24,  1.62it/s]\n",
            "Iteration:  59% 54/92 [00:33<00:23,  1.61it/s]\n",
            "Iteration:  60% 55/92 [00:33<00:22,  1.62it/s]\n",
            "Iteration:  61% 56/92 [00:34<00:22,  1.61it/s]\n",
            "Iteration:  62% 57/92 [00:35<00:21,  1.61it/s]\n",
            "Iteration:  63% 58/92 [00:35<00:21,  1.61it/s]\n",
            "Iteration:  64% 59/92 [00:36<00:20,  1.61it/s]\n",
            "Iteration:  65% 60/92 [00:37<00:19,  1.61it/s]\n",
            "Iteration:  66% 61/92 [00:37<00:19,  1.60it/s]\n",
            "Iteration:  67% 62/92 [00:38<00:18,  1.61it/s]\n",
            "Iteration:  68% 63/92 [00:38<00:17,  1.62it/s]\n",
            "Iteration:  70% 64/92 [00:39<00:17,  1.61it/s]\n",
            "Iteration:  71% 65/92 [00:40<00:16,  1.61it/s]\n",
            "Iteration:  72% 66/92 [00:40<00:16,  1.61it/s]\n",
            "Iteration:  73% 67/92 [00:41<00:15,  1.61it/s]\n",
            "Iteration:  74% 68/92 [00:42<00:14,  1.61it/s]\n",
            "Iteration:  75% 69/92 [00:42<00:14,  1.61it/s]\n",
            "Iteration:  76% 70/92 [00:43<00:13,  1.61it/s]\n",
            "Iteration:  77% 71/92 [00:43<00:13,  1.61it/s]\n",
            "Iteration:  78% 72/92 [00:44<00:12,  1.61it/s]\n",
            "Iteration:  79% 73/92 [00:45<00:11,  1.61it/s]\n",
            "Iteration:  80% 74/92 [00:45<00:11,  1.60it/s]\n",
            "Iteration:  82% 75/92 [00:46<00:10,  1.60it/s]\n",
            "Iteration:  83% 76/92 [00:47<00:09,  1.61it/s]\n",
            "Iteration:  84% 77/92 [00:47<00:09,  1.60it/s]\n",
            "Iteration:  85% 78/92 [00:48<00:08,  1.61it/s]\n",
            "Iteration:  86% 79/92 [00:48<00:08,  1.60it/s]\n",
            "Iteration:  87% 80/92 [00:49<00:07,  1.60it/s]\n",
            "Iteration:  88% 81/92 [00:50<00:06,  1.59it/s]\n",
            "Iteration:  89% 82/92 [00:50<00:06,  1.60it/s]\n",
            "Iteration:  90% 83/92 [00:51<00:05,  1.60it/s]\n",
            "Iteration:  91% 84/92 [00:52<00:04,  1.60it/s]\n",
            "Iteration:  92% 85/92 [00:52<00:04,  1.60it/s]\n",
            "Iteration:  93% 86/92 [00:53<00:03,  1.60it/s]\n",
            "Iteration:  95% 87/92 [00:53<00:03,  1.60it/s]\n",
            "Iteration:  96% 88/92 [00:54<00:02,  1.60it/s]\n",
            "Iteration:  97% 89/92 [00:55<00:01,  1.60it/s]\n",
            "Iteration:  98% 90/92 [00:55<00:01,  1.59it/s]\n",
            "Iteration:  99% 91/92 [00:56<00:00,  1.58it/s]\n",
            "Iteration: 100% 92/92 [00:57<00:00,  1.61it/s]\n",
            "Epoch:  20% 1/5 [00:57<03:48, 57.07s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\n",
            "Iteration:   1% 1/92 [00:00<00:57,  1.59it/s]\n",
            "Iteration:   2% 2/92 [00:01<00:56,  1.59it/s]\n",
            "Iteration:   3% 3/92 [00:01<00:55,  1.59it/s]\n",
            "Iteration:   4% 4/92 [00:02<00:55,  1.59it/s]\n",
            "Iteration:   5% 5/92 [00:03<00:54,  1.59it/s]\n",
            "Iteration:   7% 6/92 [00:03<00:53,  1.60it/s]\n",
            "Iteration:   8% 7/92 [00:04<00:53,  1.59it/s]\n",
            "Iteration:   9% 8/92 [00:05<00:52,  1.60it/s]\n",
            "Iteration:  10% 9/92 [00:05<00:52,  1.59it/s]\n",
            "Iteration:  11% 10/92 [00:06<00:51,  1.59it/s]\n",
            "Iteration:  12% 11/92 [00:06<00:50,  1.59it/s]\n",
            "Iteration:  13% 12/92 [00:07<00:50,  1.59it/s]\n",
            "Iteration:  14% 13/92 [00:08<00:49,  1.59it/s]\n",
            "Iteration:  15% 14/92 [00:08<00:48,  1.59it/s]\n",
            "Iteration:  16% 15/92 [00:09<00:48,  1.59it/s]\n",
            "Iteration:  17% 16/92 [00:10<00:47,  1.59it/s]\n",
            "Iteration:  18% 17/92 [00:10<00:47,  1.58it/s]\n",
            "Iteration:  20% 18/92 [00:11<00:46,  1.58it/s]\n",
            "Iteration:  21% 19/92 [00:11<00:46,  1.58it/s]\n",
            "Iteration:  22% 20/92 [00:12<00:45,  1.57it/s]\n",
            "Iteration:  23% 21/92 [00:13<00:44,  1.58it/s]\n",
            "Iteration:  24% 22/92 [00:13<00:44,  1.58it/s]\n",
            "Iteration:  25% 23/92 [00:14<00:43,  1.57it/s]\n",
            "Iteration:  26% 24/92 [00:15<00:43,  1.58it/s]\n",
            "Iteration:  27% 25/92 [00:15<00:42,  1.58it/s]\n",
            "Iteration:  28% 26/92 [00:16<00:41,  1.57it/s]\n",
            "Iteration:  29% 27/92 [00:17<00:41,  1.58it/s]\n",
            "Iteration:  30% 28/92 [00:17<00:40,  1.58it/s]\n",
            "Iteration:  32% 29/92 [00:18<00:39,  1.58it/s]\n",
            "Iteration:  33% 30/92 [00:18<00:39,  1.57it/s]\n",
            "Iteration:  34% 31/92 [00:19<00:38,  1.57it/s]\n",
            "Iteration:  35% 32/92 [00:20<00:38,  1.58it/s]\n",
            "Iteration:  36% 33/92 [00:20<00:37,  1.58it/s]\n",
            "Iteration:  37% 34/92 [00:21<00:36,  1.57it/s]\n",
            "Iteration:  38% 35/92 [00:22<00:36,  1.57it/s]\n",
            "Iteration:  39% 36/92 [00:22<00:35,  1.57it/s]\n",
            "Iteration:  40% 37/92 [00:23<00:34,  1.58it/s]\n",
            "Iteration:  41% 38/92 [00:24<00:34,  1.57it/s]\n",
            "Iteration:  42% 39/92 [00:24<00:33,  1.57it/s]\n",
            "Iteration:  43% 40/92 [00:25<00:33,  1.58it/s]\n",
            "Iteration:  45% 41/92 [00:25<00:32,  1.57it/s]\n",
            "Iteration:  46% 42/92 [00:26<00:31,  1.57it/s]\n",
            "Iteration:  47% 43/92 [00:27<00:31,  1.57it/s]\n",
            "Iteration:  48% 44/92 [00:27<00:30,  1.57it/s]\n",
            "Iteration:  49% 45/92 [00:28<00:29,  1.57it/s]\n",
            "Iteration:  50% 46/92 [00:29<00:29,  1.57it/s]\n",
            "Iteration:  51% 47/92 [00:29<00:28,  1.57it/s]\n",
            "Iteration:  52% 48/92 [00:30<00:28,  1.56it/s]\n",
            "Iteration:  53% 49/92 [00:31<00:27,  1.57it/s]\n",
            "Iteration:  54% 50/92 [00:31<00:26,  1.56it/s]\n",
            "Iteration:  55% 51/92 [00:32<00:26,  1.57it/s]\n",
            "Iteration:  57% 52/92 [00:32<00:25,  1.57it/s]\n",
            "Iteration:  58% 53/92 [00:33<00:24,  1.57it/s]\n",
            "Iteration:  59% 54/92 [00:34<00:24,  1.57it/s]\n",
            "Iteration:  60% 55/92 [00:34<00:23,  1.57it/s]\n",
            "Iteration:  61% 56/92 [00:35<00:23,  1.56it/s]\n",
            "Iteration:  62% 57/92 [00:36<00:22,  1.56it/s]\n",
            "Iteration:  63% 58/92 [00:36<00:21,  1.56it/s]\n",
            "Iteration:  64% 59/92 [00:37<00:21,  1.55it/s]\n",
            "Iteration:  65% 60/92 [00:38<00:20,  1.56it/s]\n",
            "Iteration:  66% 61/92 [00:38<00:19,  1.55it/s]\n",
            "Iteration:  67% 62/92 [00:39<00:19,  1.56it/s]\n",
            "Iteration:  68% 63/92 [00:40<00:18,  1.56it/s]\n",
            "Iteration:  70% 64/92 [00:40<00:17,  1.56it/s]\n",
            "Iteration:  71% 65/92 [00:41<00:17,  1.56it/s]\n",
            "Iteration:  72% 66/92 [00:41<00:16,  1.55it/s]\n",
            "Iteration:  73% 67/92 [00:42<00:16,  1.55it/s]\n",
            "Iteration:  74% 68/92 [00:43<00:15,  1.55it/s]\n",
            "Iteration:  75% 69/92 [00:43<00:14,  1.55it/s]\n",
            "Iteration:  76% 70/92 [00:44<00:14,  1.55it/s]\n",
            "Iteration:  77% 71/92 [00:45<00:13,  1.55it/s]\n",
            "Iteration:  78% 72/92 [00:45<00:12,  1.55it/s]\n",
            "Iteration:  79% 73/92 [00:46<00:12,  1.55it/s]\n",
            "Iteration:  80% 74/92 [00:47<00:11,  1.55it/s]\n",
            "Iteration:  82% 75/92 [00:47<00:11,  1.55it/s]\n",
            "Iteration:  83% 76/92 [00:48<00:10,  1.54it/s]\n",
            "Iteration:  84% 77/92 [00:49<00:09,  1.54it/s]\n",
            "Iteration:  85% 78/92 [00:49<00:09,  1.54it/s]\n",
            "Iteration:  86% 79/92 [00:50<00:08,  1.55it/s]\n",
            "Iteration:  87% 80/92 [00:50<00:07,  1.55it/s]\n",
            "Iteration:  88% 81/92 [00:51<00:07,  1.55it/s]\n",
            "Iteration:  89% 82/92 [00:52<00:06,  1.55it/s]\n",
            "Iteration:  90% 83/92 [00:52<00:05,  1.54it/s]\n",
            "Iteration:  91% 84/92 [00:53<00:05,  1.54it/s]\n",
            "Iteration:  92% 85/92 [00:54<00:04,  1.54it/s]\n",
            "Iteration:  93% 86/92 [00:54<00:03,  1.53it/s]\n",
            "Iteration:  95% 87/92 [00:55<00:03,  1.53it/s]\n",
            "Iteration:  96% 88/92 [00:56<00:02,  1.54it/s]\n",
            "Iteration:  97% 89/92 [00:56<00:01,  1.54it/s]\n",
            "Iteration:  98% 90/92 [00:57<00:01,  1.54it/s]\n",
            "Iteration:  99% 91/92 [00:58<00:00,  1.54it/s]\n",
            "Iteration: 100% 92/92 [00:58<00:00,  1.56it/s]\n",
            "Epoch:  40% 2/5 [01:55<02:52, 57.59s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\n",
            "Iteration:   1% 1/92 [00:00<00:59,  1.52it/s]\n",
            "Iteration:   2% 2/92 [00:01<00:58,  1.53it/s]\n",
            "Iteration:   3% 3/92 [00:01<00:58,  1.53it/s]\n",
            "Iteration:   4% 4/92 [00:02<00:57,  1.53it/s]\n",
            "Iteration:   5% 5/92 [00:03<00:56,  1.53it/s]\n",
            "Iteration:   7% 6/92 [00:03<00:56,  1.53it/s]\n",
            "Iteration:   8% 7/92 [00:04<00:55,  1.53it/s]\n",
            "Iteration:   9% 8/92 [00:05<00:55,  1.52it/s]\n",
            "Iteration:  10% 9/92 [00:05<00:54,  1.52it/s]\n",
            "Iteration:  11% 10/92 [00:06<00:53,  1.53it/s]\n",
            "Iteration:  12% 11/92 [00:07<00:52,  1.53it/s]\n",
            "Iteration:  13% 12/92 [00:07<00:52,  1.51it/s]\n",
            "Iteration:  14% 13/92 [00:08<00:51,  1.53it/s]\n",
            "Iteration:  15% 14/92 [00:09<00:51,  1.52it/s]\n",
            "Iteration:  16% 15/92 [00:09<00:50,  1.53it/s]\n",
            "Iteration:  17% 16/92 [00:10<00:49,  1.52it/s]\n",
            "Iteration:  18% 17/92 [00:11<00:49,  1.53it/s]\n",
            "Iteration:  20% 18/92 [00:11<00:48,  1.53it/s]\n",
            "Iteration:  21% 19/92 [00:12<00:48,  1.51it/s]\n",
            "Iteration:  22% 20/92 [00:13<00:47,  1.53it/s]\n",
            "Iteration:  23% 21/92 [00:13<00:46,  1.52it/s]\n",
            "Iteration:  24% 22/92 [00:14<00:45,  1.53it/s]\n",
            "Iteration:  25% 23/92 [00:15<00:45,  1.53it/s]\n",
            "Iteration:  26% 24/92 [00:15<00:44,  1.52it/s]\n",
            "Iteration:  27% 25/92 [00:16<00:44,  1.52it/s]\n",
            "Iteration:  28% 26/92 [00:17<00:43,  1.52it/s]\n",
            "Iteration:  29% 27/92 [00:17<00:42,  1.53it/s]\n",
            "Iteration:  30% 28/92 [00:18<00:41,  1.53it/s]\n",
            "Iteration:  32% 29/92 [00:19<00:41,  1.53it/s]\n",
            "Iteration:  33% 30/92 [00:19<00:40,  1.53it/s]\n",
            "Iteration:  34% 31/92 [00:20<00:40,  1.52it/s]\n",
            "Iteration:  35% 32/92 [00:20<00:39,  1.53it/s]\n",
            "Iteration:  36% 33/92 [00:21<00:38,  1.53it/s]\n",
            "Iteration:  37% 34/92 [00:22<00:38,  1.52it/s]\n",
            "Iteration:  38% 35/92 [00:22<00:37,  1.54it/s]\n",
            "Iteration:  39% 36/92 [00:23<00:36,  1.54it/s]\n",
            "Iteration:  40% 37/92 [00:24<00:35,  1.54it/s]\n",
            "Iteration:  41% 38/92 [00:24<00:35,  1.54it/s]\n",
            "Iteration:  42% 39/92 [00:25<00:34,  1.53it/s]\n",
            "Iteration:  43% 40/92 [00:26<00:33,  1.54it/s]\n",
            "Iteration:  45% 41/92 [00:26<00:33,  1.54it/s]\n",
            "Iteration:  46% 42/92 [00:27<00:32,  1.54it/s]\n",
            "Iteration:  47% 43/92 [00:28<00:31,  1.55it/s]\n",
            "Iteration:  48% 44/92 [00:28<00:31,  1.54it/s]\n",
            "Iteration:  49% 45/92 [00:29<00:30,  1.54it/s]\n",
            "Iteration:  50% 46/92 [00:30<00:29,  1.54it/s]\n",
            "Iteration:  51% 47/92 [00:30<00:29,  1.54it/s]\n",
            "Iteration:  52% 48/92 [00:31<00:28,  1.55it/s]\n",
            "Iteration:  53% 49/92 [00:32<00:27,  1.54it/s]\n",
            "Iteration:  54% 50/92 [00:32<00:27,  1.54it/s]\n",
            "Iteration:  55% 51/92 [00:33<00:26,  1.55it/s]\n",
            "Iteration:  57% 52/92 [00:33<00:25,  1.54it/s]\n",
            "Iteration:  58% 53/92 [00:34<00:25,  1.53it/s]\n",
            "Iteration:  59% 54/92 [00:35<00:24,  1.54it/s]\n",
            "Iteration:  60% 55/92 [00:35<00:23,  1.55it/s]\n",
            "Iteration:  61% 56/92 [00:36<00:23,  1.55it/s]\n",
            "Iteration:  62% 57/92 [00:37<00:22,  1.54it/s]\n",
            "Iteration:  63% 58/92 [00:37<00:21,  1.55it/s]\n",
            "Iteration:  64% 59/92 [00:38<00:21,  1.55it/s]\n",
            "Iteration:  65% 60/92 [00:39<00:20,  1.55it/s]\n",
            "Iteration:  66% 61/92 [00:39<00:20,  1.55it/s]\n",
            "Iteration:  67% 62/92 [00:40<00:19,  1.54it/s]\n",
            "Iteration:  68% 63/92 [00:41<00:18,  1.55it/s]\n",
            "Iteration:  70% 64/92 [00:41<00:18,  1.54it/s]\n",
            "Iteration:  71% 65/92 [00:42<00:17,  1.54it/s]\n",
            "Iteration:  72% 66/92 [00:43<00:16,  1.55it/s]\n",
            "Iteration:  73% 67/92 [00:43<00:16,  1.55it/s]\n",
            "Iteration:  74% 68/92 [00:44<00:15,  1.54it/s]\n",
            "Iteration:  75% 69/92 [00:44<00:14,  1.55it/s]\n",
            "Iteration:  76% 70/92 [00:45<00:14,  1.55it/s]\n",
            "Iteration:  77% 71/92 [00:46<00:13,  1.54it/s]\n",
            "Iteration:  78% 72/92 [00:46<00:12,  1.55it/s]\n",
            "Iteration:  79% 73/92 [00:47<00:12,  1.54it/s]\n",
            "Iteration:  80% 74/92 [00:48<00:11,  1.55it/s]\n",
            "Iteration:  82% 75/92 [00:48<00:11,  1.54it/s]\n",
            "Iteration:  83% 76/92 [00:49<00:10,  1.55it/s]\n",
            "Iteration:  84% 77/92 [00:50<00:09,  1.55it/s]\n",
            "Iteration:  85% 78/92 [00:50<00:09,  1.55it/s]\n",
            "Iteration:  86% 79/92 [00:51<00:08,  1.55it/s]\n",
            "Iteration:  87% 80/92 [00:52<00:07,  1.54it/s]\n",
            "Iteration:  88% 81/92 [00:52<00:07,  1.55it/s]\n",
            "Iteration:  89% 82/92 [00:53<00:06,  1.55it/s]\n",
            "Iteration:  90% 83/92 [00:54<00:05,  1.55it/s]\n",
            "Iteration:  91% 84/92 [00:54<00:05,  1.55it/s]\n",
            "Iteration:  92% 85/92 [00:55<00:04,  1.54it/s]\n",
            "Iteration:  93% 86/92 [00:55<00:03,  1.55it/s]\n",
            "Iteration:  95% 87/92 [00:56<00:03,  1.55it/s]\n",
            "Iteration:  96% 88/92 [00:57<00:02,  1.55it/s]\n",
            "Iteration:  97% 89/92 [00:57<00:01,  1.54it/s]\n",
            "Iteration:  98% 90/92 [00:58<00:01,  1.55it/s]\n",
            "Iteration:  99% 91/92 [00:59<00:00,  1.54it/s]\n",
            "Iteration: 100% 92/92 [00:59<00:00,  1.54it/s]\n",
            "Epoch:  60% 3/5 [02:55<01:56, 58.27s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\n",
            "Iteration:   1% 1/92 [00:00<00:59,  1.52it/s]\n",
            "Iteration:   2% 2/92 [00:01<00:58,  1.53it/s]\n",
            "Iteration:   3% 3/92 [00:01<00:57,  1.54it/s]\n",
            "Iteration:   4% 4/92 [00:02<00:57,  1.54it/s]\n",
            "Iteration:   5% 5/92 [00:03<00:56,  1.54it/s]\n",
            "Iteration:   7% 6/92 [00:03<00:55,  1.54it/s]\n",
            "Iteration:   8% 7/92 [00:04<00:55,  1.54it/s]\n",
            "Iteration:   9% 8/92 [00:05<00:54,  1.54it/s]\n",
            "Iteration:  10% 9/92 [00:05<00:53,  1.54it/s]\n",
            "Iteration:  11% 10/92 [00:06<00:53,  1.54it/s]\n",
            "Iteration:  12% 11/92 [00:07<00:52,  1.54it/s]\n",
            "Iteration:  13% 12/92 [00:07<00:51,  1.54it/s]\n",
            "Iteration:  14% 13/92 [00:08<00:51,  1.54it/s]\n",
            "Iteration:  15% 14/92 [00:09<00:50,  1.54it/s]\n",
            "Iteration:  16% 15/92 [00:09<00:49,  1.55it/s]\n",
            "Iteration:  17% 16/92 [00:10<00:49,  1.54it/s]\n",
            "Iteration:  18% 17/92 [00:11<00:48,  1.54it/s]\n",
            "Iteration:  20% 18/92 [00:11<00:47,  1.54it/s]\n",
            "Iteration:  21% 19/92 [00:12<00:47,  1.54it/s]\n",
            "Iteration:  22% 20/92 [00:12<00:46,  1.53it/s]\n",
            "Iteration:  23% 21/92 [00:13<00:46,  1.54it/s]\n",
            "Iteration:  24% 22/92 [00:14<00:45,  1.54it/s]\n",
            "Iteration:  25% 23/92 [00:14<00:45,  1.53it/s]\n",
            "Iteration:  26% 24/92 [00:15<00:44,  1.54it/s]\n",
            "Iteration:  27% 25/92 [00:16<00:43,  1.54it/s]\n",
            "Iteration:  28% 26/92 [00:16<00:43,  1.53it/s]\n",
            "Iteration:  29% 27/92 [00:17<00:42,  1.53it/s]\n",
            "Iteration:  30% 28/92 [00:18<00:41,  1.54it/s]\n",
            "Iteration:  32% 29/92 [00:18<00:41,  1.53it/s]\n",
            "Iteration:  33% 30/92 [00:19<00:40,  1.54it/s]\n",
            "Iteration:  34% 31/92 [00:20<00:39,  1.54it/s]\n",
            "Iteration:  35% 32/92 [00:20<00:39,  1.54it/s]\n",
            "Iteration:  36% 33/92 [00:21<00:38,  1.54it/s]\n",
            "Iteration:  37% 34/92 [00:22<00:37,  1.54it/s]\n",
            "Iteration:  38% 35/92 [00:22<00:36,  1.54it/s]\n",
            "Iteration:  39% 36/92 [00:23<00:36,  1.53it/s]\n",
            "Iteration:  40% 37/92 [00:24<00:35,  1.54it/s]\n",
            "Iteration:  41% 38/92 [00:24<00:35,  1.54it/s]\n",
            "Iteration:  42% 39/92 [00:25<00:34,  1.54it/s]\n",
            "Iteration:  43% 40/92 [00:25<00:33,  1.54it/s]\n",
            "Iteration:  45% 41/92 [00:26<00:33,  1.53it/s]\n",
            "Iteration:  46% 42/92 [00:27<00:32,  1.54it/s]\n",
            "Iteration:  47% 43/92 [00:27<00:31,  1.53it/s]\n",
            "Iteration:  48% 44/92 [00:28<00:31,  1.53it/s]\n",
            "Iteration:  49% 45/92 [00:29<00:30,  1.53it/s]\n",
            "Iteration:  50% 46/92 [00:29<00:29,  1.54it/s]\n",
            "Iteration:  51% 47/92 [00:30<00:29,  1.54it/s]\n",
            "Iteration:  52% 48/92 [00:31<00:28,  1.54it/s]\n",
            "Iteration:  53% 49/92 [00:31<00:27,  1.54it/s]\n",
            "Iteration:  54% 50/92 [00:32<00:27,  1.54it/s]\n",
            "Iteration:  55% 51/92 [00:33<00:26,  1.54it/s]\n",
            "Iteration:  57% 52/92 [00:33<00:25,  1.54it/s]\n",
            "Iteration:  58% 53/92 [00:34<00:25,  1.54it/s]\n",
            "Iteration:  59% 54/92 [00:35<00:24,  1.54it/s]\n",
            "Iteration:  60% 55/92 [00:35<00:23,  1.54it/s]\n",
            "Iteration:  61% 56/92 [00:36<00:23,  1.54it/s]\n",
            "Iteration:  62% 57/92 [00:37<00:22,  1.54it/s]\n",
            "Iteration:  63% 58/92 [00:37<00:22,  1.54it/s]\n",
            "Iteration:  64% 59/92 [00:38<00:21,  1.54it/s]\n",
            "Iteration:  65% 60/92 [00:38<00:20,  1.54it/s]\n",
            "Iteration:  66% 61/92 [00:39<00:20,  1.53it/s]\n",
            "Iteration:  67% 62/92 [00:40<00:19,  1.53it/s]\n",
            "Iteration:  68% 63/92 [00:40<00:18,  1.53it/s]\n",
            "Iteration:  70% 64/92 [00:41<00:18,  1.54it/s]\n",
            "Iteration:  71% 65/92 [00:42<00:17,  1.54it/s]\n",
            "Iteration:  72% 66/92 [00:42<00:16,  1.54it/s]\n",
            "Iteration:  73% 67/92 [00:43<00:16,  1.54it/s]\n",
            "Iteration:  74% 68/92 [00:44<00:15,  1.54it/s]\n",
            "Iteration:  75% 69/92 [00:44<00:14,  1.54it/s]\n",
            "Iteration:  76% 70/92 [00:45<00:14,  1.54it/s]\n",
            "Iteration:  77% 71/92 [00:46<00:13,  1.53it/s]\n",
            "Iteration:  78% 72/92 [00:46<00:12,  1.54it/s]\n",
            "Iteration:  79% 73/92 [00:47<00:12,  1.54it/s]\n",
            "Iteration:  80% 74/92 [00:48<00:11,  1.54it/s]\n",
            "Iteration:  82% 75/92 [00:48<00:11,  1.54it/s]\n",
            "Iteration:  83% 76/92 [00:49<00:10,  1.54it/s]\n",
            "Iteration:  84% 77/92 [00:50<00:09,  1.54it/s]\n",
            "Iteration:  85% 78/92 [00:50<00:09,  1.54it/s]\n",
            "Iteration:  86% 79/92 [00:51<00:08,  1.54it/s]\n",
            "Iteration:  87% 80/92 [00:51<00:07,  1.54it/s]\n",
            "Iteration:  88% 81/92 [00:52<00:07,  1.54it/s]\n",
            "Iteration:  89% 82/92 [00:53<00:06,  1.55it/s]\n",
            "Iteration:  90% 83/92 [00:53<00:05,  1.54it/s]\n",
            "Iteration:  91% 84/92 [00:54<00:05,  1.54it/s]\n",
            "Iteration:  92% 85/92 [00:55<00:04,  1.54it/s]\n",
            "Iteration:  93% 86/92 [00:55<00:03,  1.54it/s]\n",
            "Iteration:  95% 87/92 [00:56<00:03,  1.54it/s]\n",
            "Iteration:  96% 88/92 [00:57<00:02,  1.54it/s]\n",
            "Iteration:  97% 89/92 [00:57<00:01,  1.54it/s]\n",
            "Iteration:  98% 90/92 [00:58<00:01,  1.54it/s]\n",
            "Iteration:  99% 91/92 [00:59<00:00,  1.54it/s]\n",
            "Iteration: 100% 92/92 [00:59<00:00,  1.54it/s]\n",
            "Epoch:  80% 4/5 [03:55<00:58, 58.72s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\n",
            "Iteration:   1% 1/92 [00:00<00:58,  1.56it/s]\n",
            "Iteration:   2% 2/92 [00:01<00:57,  1.55it/s]\n",
            "Iteration:   3% 3/92 [00:01<00:57,  1.55it/s]\n",
            "Iteration:   4% 4/92 [00:02<00:57,  1.54it/s]\n",
            "Iteration:   5% 5/92 [00:03<00:56,  1.55it/s]\n",
            "Iteration:   7% 6/92 [00:03<00:55,  1.54it/s]\n",
            "Iteration:   8% 7/92 [00:04<00:54,  1.55it/s]\n",
            "Iteration:   9% 8/92 [00:05<00:54,  1.55it/s]\n",
            "Iteration:  10% 9/92 [00:05<00:53,  1.55it/s]\n",
            "Iteration:  11% 10/92 [00:06<00:53,  1.55it/s]\n",
            "Iteration:  12% 11/92 [00:07<00:52,  1.54it/s]\n",
            "Iteration:  13% 12/92 [00:07<00:51,  1.54it/s]\n",
            "Iteration:  14% 13/92 [00:08<00:51,  1.54it/s]\n",
            "Iteration:  15% 14/92 [00:09<00:50,  1.55it/s]\n",
            "Iteration:  16% 15/92 [00:09<00:50,  1.54it/s]\n",
            "Iteration:  17% 16/92 [00:10<00:49,  1.55it/s]\n",
            "Iteration:  18% 17/92 [00:11<00:48,  1.55it/s]\n",
            "Iteration:  20% 18/92 [00:11<00:47,  1.55it/s]\n",
            "Iteration:  21% 19/92 [00:12<00:47,  1.54it/s]\n",
            "Iteration:  22% 20/92 [00:12<00:46,  1.54it/s]\n",
            "Iteration:  23% 21/92 [00:13<00:45,  1.54it/s]\n",
            "Iteration:  24% 22/92 [00:14<00:45,  1.53it/s]\n",
            "Iteration:  25% 23/92 [00:14<00:44,  1.55it/s]\n",
            "Iteration:  26% 24/92 [00:15<00:44,  1.54it/s]\n",
            "Iteration:  27% 25/92 [00:16<00:43,  1.54it/s]\n",
            "Iteration:  28% 26/92 [00:16<00:42,  1.55it/s]\n",
            "Iteration:  29% 27/92 [00:17<00:42,  1.55it/s]\n",
            "Iteration:  30% 28/92 [00:18<00:41,  1.55it/s]\n",
            "Iteration:  32% 29/92 [00:18<00:40,  1.55it/s]\n",
            "Iteration:  33% 30/92 [00:19<00:40,  1.54it/s]\n",
            "Iteration:  34% 31/92 [00:20<00:39,  1.54it/s]\n",
            "Iteration:  35% 32/92 [00:20<00:38,  1.54it/s]\n",
            "Iteration:  36% 33/92 [00:21<00:38,  1.54it/s]\n",
            "Iteration:  37% 34/92 [00:22<00:37,  1.54it/s]\n",
            "Iteration:  38% 35/92 [00:22<00:36,  1.54it/s]\n",
            "Iteration:  39% 36/92 [00:23<00:36,  1.54it/s]\n",
            "Iteration:  40% 37/92 [00:23<00:35,  1.54it/s]\n",
            "Iteration:  41% 38/92 [00:24<00:34,  1.54it/s]\n",
            "Iteration:  42% 39/92 [00:25<00:34,  1.54it/s]\n",
            "Iteration:  43% 40/92 [00:25<00:33,  1.54it/s]\n",
            "Iteration:  45% 41/92 [00:26<00:33,  1.54it/s]\n",
            "Iteration:  46% 42/92 [00:27<00:32,  1.54it/s]\n",
            "Iteration:  47% 43/92 [00:27<00:31,  1.54it/s]\n",
            "Iteration:  48% 44/92 [00:28<00:31,  1.54it/s]\n",
            "Iteration:  49% 45/92 [00:29<00:30,  1.54it/s]\n",
            "Iteration:  50% 46/92 [00:29<00:29,  1.54it/s]\n",
            "Iteration:  51% 47/92 [00:30<00:29,  1.54it/s]\n",
            "Iteration:  52% 48/92 [00:31<00:28,  1.55it/s]\n",
            "Iteration:  53% 49/92 [00:31<00:27,  1.54it/s]\n",
            "Iteration:  54% 50/92 [00:32<00:27,  1.54it/s]\n",
            "Iteration:  55% 51/92 [00:33<00:26,  1.54it/s]\n",
            "Iteration:  57% 52/92 [00:33<00:25,  1.55it/s]\n",
            "Iteration:  58% 53/92 [00:34<00:25,  1.55it/s]\n",
            "Iteration:  59% 54/92 [00:34<00:24,  1.54it/s]\n",
            "Iteration:  60% 55/92 [00:35<00:23,  1.54it/s]\n",
            "Iteration:  61% 56/92 [00:36<00:23,  1.54it/s]\n",
            "Iteration:  62% 57/92 [00:36<00:22,  1.54it/s]\n",
            "Iteration:  63% 58/92 [00:37<00:22,  1.54it/s]\n",
            "Iteration:  64% 59/92 [00:38<00:21,  1.54it/s]\n",
            "Iteration:  65% 60/92 [00:38<00:20,  1.54it/s]\n",
            "Iteration:  66% 61/92 [00:39<00:20,  1.53it/s]\n",
            "Iteration:  67% 62/92 [00:40<00:19,  1.54it/s]\n",
            "Iteration:  68% 63/92 [00:40<00:18,  1.53it/s]\n",
            "Iteration:  70% 64/92 [00:41<00:18,  1.53it/s]\n",
            "Iteration:  71% 65/92 [00:42<00:17,  1.54it/s]\n",
            "Iteration:  72% 66/92 [00:42<00:16,  1.54it/s]\n",
            "Iteration:  73% 67/92 [00:43<00:16,  1.53it/s]\n",
            "Iteration:  74% 68/92 [00:44<00:15,  1.54it/s]\n",
            "Iteration:  75% 69/92 [00:44<00:14,  1.54it/s]\n",
            "Iteration:  76% 70/92 [00:45<00:14,  1.54it/s]\n",
            "Iteration:  77% 71/92 [00:46<00:13,  1.53it/s]\n",
            "Iteration:  78% 72/92 [00:46<00:13,  1.53it/s]\n",
            "Iteration:  79% 73/92 [00:47<00:12,  1.53it/s]\n",
            "Iteration:  80% 74/92 [00:48<00:11,  1.54it/s]\n",
            "Iteration:  82% 75/92 [00:48<00:11,  1.54it/s]\n",
            "Iteration:  83% 76/92 [00:49<00:10,  1.53it/s]\n",
            "Iteration:  84% 77/92 [00:49<00:09,  1.54it/s]\n",
            "Iteration:  85% 78/92 [00:50<00:09,  1.52it/s]\n",
            "Iteration:  86% 79/92 [00:51<00:08,  1.53it/s]\n",
            "Iteration:  87% 80/92 [00:51<00:07,  1.53it/s]\n",
            "Iteration:  88% 81/92 [00:52<00:07,  1.53it/s]\n",
            "Iteration:  89% 82/92 [00:53<00:06,  1.53it/s]\n",
            "Iteration:  90% 83/92 [00:53<00:05,  1.54it/s]\n",
            "Iteration:  91% 84/92 [00:54<00:05,  1.53it/s]\n",
            "Iteration:  92% 85/92 [00:55<00:04,  1.53it/s]\n",
            "Iteration:  93% 86/92 [00:55<00:03,  1.53it/s]\n",
            "Iteration:  95% 87/92 [00:56<00:03,  1.53it/s]\n",
            "Iteration:  96% 88/92 [00:57<00:02,  1.54it/s]\n",
            "Iteration:  97% 89/92 [00:57<00:01,  1.54it/s]\n",
            "Iteration:  98% 90/92 [00:58<00:01,  1.54it/s]\n",
            "Iteration:  99% 91/92 [00:59<00:00,  1.54it/s]\n",
            "Iteration: 100% 92/92 [00:59<00:00,  1.54it/s]\n",
            "Epoch: 100% 5/5 [04:55<00:00, 59.05s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4tcIfvP7gAb"
      },
      "source": [
        "# Poetry generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21IywMBl1Zsc"
      },
      "source": [
        "def generate_poetry(model):\r\n",
        "    prompt_text = input(\"Context > \")\r\n",
        "    \r\n",
        "    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\")\r\n",
        "    generated_sequences = []\r\n",
        "\r\n",
        "    output_sequences = model.generate(\r\n",
        "        input_ids=encoded_prompt,\r\n",
        "        max_length=100 + len(encoded_prompt[0]),\r\n",
        "        temperature=0.7,\r\n",
        "        top_k=0,\r\n",
        "        top_p=0.9,\r\n",
        "        repetition_penalty=1.0,\r\n",
        "        do_sample=True,\r\n",
        "        num_return_sequences=1,\r\n",
        "    )\r\n",
        "\r\n",
        "    \r\n",
        "    if len(output_sequences.shape) > 2:\r\n",
        "        output_sequences.squeeze_()\r\n",
        "\r\n",
        "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\r\n",
        "        generated_sequence = generated_sequence.tolist()\r\n",
        "\r\n",
        "        # Decode text\r\n",
        "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\r\n",
        "\r\n",
        "        # Remove all text after the stop token\r\n",
        "        stop_token = '</s>'\r\n",
        "        text = text[: text.find(stop_token) if stop_token else None]\r\n",
        "\r\n",
        "        # Add the prompt at the beginning of the sequence. Remove the excess text that was used for pre-processing\r\n",
        "        total_sequence = (\r\n",
        "            prompt_text + text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True)) :]\r\n",
        "        )\r\n",
        "\r\n",
        "        generated_sequences.append(total_sequence)\r\n",
        "\r\n",
        "    return generated_sequences"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_JQKSID9JuB",
        "outputId": "eb7a1402-a334-49bb-82d1-40df7bafc51b"
      },
      "source": [
        "print(generate_poetry(model))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context > Я иду по лесу и вижу лису\n",
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "['Я иду по лесу и вижу лису. Продрогшая — бьет по земле хвостом. Я увидел — глаза ослепли от страха...Что это? Стихи или только рассказ? А за ним новый рассказ-сказка!.. Грустные, грозовые, страстные, мчатся в песне весенней.Пристально слушает лиса.А я иду по лесу...Он похож на мир людей... Так! Он грустен, но жив!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbu4zBX6AFV6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}